{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import grid_search\n",
    "from sklearn import tree\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segmentWords(s): \n",
    "    return s.split()\n",
    "\n",
    "def readFile(fileName):\n",
    "    # Function for reading file\n",
    "    # input: filename as string\n",
    "    # output: contents of file as list containing single words\n",
    "    contents = []\n",
    "    f = open(fileName)\n",
    "    for line in f:\n",
    "        contents.append(line)\n",
    "    f.close()\n",
    "    result = segmentWords('\\n'.join(contents))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Dataframe containing the counts of each word in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = []\n",
    "\n",
    "for c in os.listdir(\"data_training/train\"):\n",
    "    directory = \"data_training/train/\" + c\n",
    "    for f in os.listdir(directory):\n",
    "        words = readFile(directory + \"/\" + f)\n",
    "        e = {x:words.count(x) for x in words}\n",
    "        e['__FileID__'] = f\n",
    "        e['__CLASS__'] = 1 if c[:3] == 'pos' else 0\n",
    "        d.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dataframe from d - make sure to fill all the nan values with zeros.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(d).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 42776)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\u0005</th>\n",
       "      <th>\u0013earth</th>\n",
       "      <th>\u0013goodies</th>\n",
       "      <th>\u0013if</th>\n",
       "      <th>\u0013ripley</th>\n",
       "      <th>\u0013suspend</th>\n",
       "      <th>\u0013they</th>\n",
       "      <th>\u0013white\u0014</th>\n",
       "      <th>\u0014</th>\n",
       "      <th>\u0016</th>\n",
       "      <th>...</th>\n",
       "      <th>zukovsky</th>\n",
       "      <th>zundel</th>\n",
       "      <th>zurg's</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwick's</th>\n",
       "      <th>zwigoff's</th>\n",
       "      <th>zycie</th>\n",
       "      <th>zycie'</th>\n",
       "      <th>|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42776 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     \u0005  \u0013earth  \u0013goodies  \u0013if  \u0013ripley  \u0013suspend  \u0013they  \u0013white\u0014    \u0014    \u0016  \\\n",
       "0  0.0     0.0       0.0  0.0      0.0       0.0    0.0      0.0  0.0  0.0   \n",
       "1  0.0     0.0       0.0  0.0      0.0       0.0    0.0      0.0  0.0  0.0   \n",
       "2  0.0     0.0       0.0  0.0      0.0       0.0    0.0      0.0  0.0  0.0   \n",
       "3  0.0     0.0       0.0  0.0      0.0       0.0    0.0      0.0  0.0  0.0   \n",
       "4  0.0     0.0       0.0  0.0      0.0       0.0    0.0      0.0  0.0  0.0   \n",
       "\n",
       "  ...   zukovsky  zundel  zurg's  zweibel  zwick  zwick's  zwigoff's  zycie  \\\n",
       "0 ...        0.0     0.0     0.0      0.0    0.0      0.0        0.0    0.0   \n",
       "1 ...        0.0     0.0     0.0      0.0    0.0      0.0        0.0    0.0   \n",
       "2 ...        0.0     0.0     0.0      0.0    0.0      0.0        0.0    0.0   \n",
       "3 ...        0.0     0.0     0.0      0.0    0.0      0.0        0.0    0.0   \n",
       "4 ...        0.0     0.0     0.0      0.0    0.0      0.0        0.0    0.0   \n",
       "\n",
       "   zycie'    |  \n",
       "0     0.0  0.0  \n",
       "1     0.0  0.0  \n",
       "2     0.0  0.0  \n",
       "3     0.0  0.0  \n",
       "4     0.0  0.0  \n",
       "\n",
       "[5 rows x 42776 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\u0005</th>\n",
       "      <th>\u0013earth</th>\n",
       "      <th>\u0013goodies</th>\n",
       "      <th>\u0013if</th>\n",
       "      <th>\u0013ripley</th>\n",
       "      <th>\u0013suspend</th>\n",
       "      <th>\u0013they</th>\n",
       "      <th>\u0013white\u0014</th>\n",
       "      <th>\u0014</th>\n",
       "      <th>\u0016</th>\n",
       "      <th>...</th>\n",
       "      <th>zukovsky</th>\n",
       "      <th>zundel</th>\n",
       "      <th>zurg's</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwick's</th>\n",
       "      <th>zwigoff's</th>\n",
       "      <th>zycie</th>\n",
       "      <th>zycie'</th>\n",
       "      <th>|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.006429</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.001429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.080127</td>\n",
       "      <td>0.272517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.053452</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.128058</td>\n",
       "      <td>0.065426</td>\n",
       "      <td>0.037783</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.037783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 42775 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 \u0005       \u0013earth     \u0013goodies          \u0013if      \u0013ripley  \\\n",
       "count  1400.000000  1400.000000  1400.000000  1400.000000  1400.000000   \n",
       "mean      0.000714     0.000714     0.000714     0.000714     0.000714   \n",
       "std       0.026726     0.026726     0.026726     0.026726     0.026726   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          \u0013suspend        \u0013they      \u0013white\u0014            \u0014            \u0016  \\\n",
       "count  1400.000000  1400.000000  1400.000000  1400.000000  1400.000000   \n",
       "mean      0.000714     0.000714     0.000714     0.003571     0.008571   \n",
       "std       0.026726     0.026726     0.026726     0.080127     0.272517   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     2.000000    10.000000   \n",
       "\n",
       "          ...          zukovsky       zundel       zurg's      zweibel  \\\n",
       "count     ...       1400.000000  1400.000000  1400.000000  1400.000000   \n",
       "mean      ...          0.000714     0.001429     0.000714     0.000714   \n",
       "std       ...          0.026726     0.053452     0.026726     0.026726   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "75%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "max       ...          1.000000     2.000000     1.000000     1.000000   \n",
       "\n",
       "             zwick      zwick's    zwigoff's        zycie       zycie'  \\\n",
       "count  1400.000000  1400.000000  1400.000000  1400.000000  1400.000000   \n",
       "mean      0.006429     0.002857     0.001429     0.000714     0.000714   \n",
       "std       0.128058     0.065426     0.037783     0.026726     0.026726   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       3.000000     2.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                 |  \n",
       "count  1400.000000  \n",
       "mean      0.001429  \n",
       "std       0.037783  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 42775 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    cv676_22202.txt\n",
      "1     cv155_7845.txt\n",
      "2    cv465_23401.txt\n",
      "3    cv398_17047.txt\n",
      "4    cv206_15893.txt\n",
      "Name: __FileID__, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1395    1\n",
       "1396    1\n",
       "1397    1\n",
       "1398    1\n",
       "1399    1\n",
       "Name: __CLASS__, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.__FileID__.head())\n",
    "df.__CLASS__.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training and validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = df.drop(['__FileID__', '__CLASS__'], axis=1)\n",
    "labels = df.__CLASS__\n",
    "X_train, X_val, Y_train, Y_val = sklearn.model_selection.train_test_split(features, labels, test_size=0.2, \n",
    "                                                                         random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1120, 42774) (280, 42774) (1120,) (280,)\n"
     ]
    }
   ],
   "source": [
    "# this step was done above before splitting data into training and validation set\n",
    "print(X_train.shape, X_val.shape, Y_train.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.0 \n",
      "Validation acc: 0.839285714286\n"
     ]
    }
   ],
   "source": [
    "logreg = sklearn.linear_model.LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "print(\"Train acc:\", logreg.score(X_train, Y_train), \"\\nValidation acc:\", \n",
    "      logreg.score(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1000, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cs = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "# gamma parameter which inversely controls the standard deviation of our kernel's distribution\n",
    "penalty = ['l1', 'l2']\n",
    "# initialize the dictionary of parameters\n",
    "param_grid = {'C': Cs, 'penalty' : penalty}\n",
    "# initialize the search using input as nfold cross validation\n",
    "lr = sklearn.linear_model.LogisticRegression()\n",
    "search = grid_search.GridSearchCV(lr, param_grid)\n",
    "# fit the search object to our input training data\n",
    "search.fit(X_train, Y_train)\n",
    "# output the best parameters\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 1.0 \n",
      "Validation acc: 0.885714285714\n"
     ]
    }
   ],
   "source": [
    "logreg2 = sklearn.linear_model.LogisticRegression(penalty='l1', C=1000)\n",
    "logreg2.fit(X_train, Y_train)\n",
    "print(\"Training acc:\", logreg2.score(X_train, Y_train), \"\\nValidation acc:\", \n",
    "      logreg2.score(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A recursive feature elimination approach\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# A new logistic regression model with parameters from above and a feature selector\n",
    "lr2 = sklearn.linear_model.LogisticRegression(C=1000, penalty='l1')\n",
    "selector = RFE(lr2, step=10000, n_features_to_select=41000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit RFE selector to training set\n",
    "selector.fit(X_train, Y_train)\n",
    "lr2 = selector.estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# figure out which columns to drop\n",
    "columns = features.columns\n",
    "feature_mask = selector.support_\n",
    "columns_to_drop = [columns[i] for i in range(columns.size) if not feature_mask[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create print function to print scores of estimators\n",
    "def print_results(estimator, X, y, leadingString=''):\n",
    "    print(leadingString, estimator.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:  1.0\n",
      "Testing results:  0.892857142857\n"
     ]
    }
   ],
   "source": [
    "# show training and testing accuracies after feature reduction\n",
    "print_results(lr2, X_train.drop(columns_to_drop, axis=1), Y_train, \"Training results: \")\n",
    "print_results(lr2, X_val.drop(columns_to_drop, axis=1), Y_val, \"Testing results: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 1.0 \n",
      "Validation acc: 0.635714285714\n"
     ]
    }
   ],
   "source": [
    "dt_clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "dt_clf.fit(X_train, Y_train)\n",
    "print(\"Training acc:\", dt_clf.score(X_train, Y_train), \"\\nValidation acc:\", dt_clf.score(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_split': [5, 10, 50, 100, 500, 1000], 'min_samples_leaf': [10, 100, 1000, 10000], 'max_depth': [None, 10, 100, 1000, 10000], 'max_leaf_nodes': [None, 10, 100, 1000, 10000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\"max_depth\": [None, 10, 100, 1000, 10000],\n",
    "              \"min_samples_split\": [5, 10, 50, 100, 500, 1000],\n",
    "              \"min_samples_leaf\": [10, 100, 1000, 10000],\n",
    "              \"max_leaf_nodes\": [None, 10, 100, 1000, 10000],\n",
    "              }\n",
    "gridsearch = GridSearchCV(dt_clf, parameters)\n",
    "gridsearch.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_leaf_nodes': 10000,\n",
       " 'min_samples_leaf': 10,\n",
       " 'min_samples_split': 100}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best parameters of the gridsearchCV regularized decision tree\n",
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 0.757142857143 \n",
      "Validation acc: 0.621428571429\n"
     ]
    }
   ],
   "source": [
    "# use parameters from gridsearchCV above in new decision tree model\n",
    "reg_tree = gridsearch.best_estimator_\n",
    "\n",
    "print(\"Training acc:\", reg_tree.score(X_train, Y_train), \"\\nValidation acc:\",\n",
    "      reg_tree.score(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.858035714286\n",
      "Testing score:  0.692857142857\n"
     ]
    }
   ],
   "source": [
    "# create decision tree model with manually searched parameters (best in class)\n",
    "reg_tree2 = tree.DecisionTreeClassifier(criterion = \"entropy\", max_depth = None, max_leaf_nodes = 125, min_samples_leaf = 2, min_samples_split = 60)\n",
    "reg_tree2.fit(X_train, Y_train)\n",
    "\n",
    "# print model training and test accuracies\n",
    "print_results(reg_tree2, X_train, Y_train, \"Training score: \")\n",
    "print_results(reg_tree2, X_val, Y_val, \"Testing score: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add a Boost to your Decision Tree Classifer using AdaBoost( )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=125,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=60,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=100, random_state=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train an AdaBoost classifier using the tuned random forest model above as the base estimator\n",
    "boost_clf = AdaBoostClassifier(base_estimator=reg_tree2, n_estimators=100)\n",
    "boost_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 1.0 \n",
      "Validation acc: 0.739285714286\n"
     ]
    }
   ],
   "source": [
    "print(\"Training acc:\", boost_clf.score(X_train, Y_train), \"\\nValidation acc:\",\n",
    "      boost_clf.score(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 1.0 \n",
      "Validation acc: 0.821428571429\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(criterion = 'entropy', n_estimators=100)\n",
    "rfc.fit(X_train, Y_train)\n",
    "print(\"Training acc:\", rfc.score(X_train, Y_train), \"\\nValidation acc:\",\n",
    "      rfc.score(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters = {\"min_samples_split\": [2, 5, 10],\n",
    "              \"max_depth\": [None, 2, 5, 10],\n",
    "              \"min_samples_leaf\": [1, 5, 10],\n",
    "              \"max_leaf_nodes\": [None, 5, 10, 20],\n",
    "              }\n",
    "gridsearch2 = GridSearchCV(rfc, parameters)\n",
    "gridsearch2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_leaf_nodes': None, 'min_samples_leaf': 10, 'min_samples_split': 100}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 0.935714285714 \n",
      "Validation acc: 0.817857142857\n"
     ]
    }
   ],
   "source": [
    "reg_forest = gridsearch2.best_estimator_\n",
    "reg_forest.fit(X_train, Y_train)\n",
    "print(\"Training acc:\", reg_forest.score(X_train, Y_train), \"\\nValidation acc:\",\n",
    "      reg_forest.score(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add a Boost to Random Forest model with sklearn's AdaBoostClassifier( )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 1.0 \n",
      "Validation acc: 0.882142857143\n"
     ]
    }
   ],
   "source": [
    "boost_reg2 = AdaBoostClassifier(base_estimator=reg_forest)\n",
    "boost_reg2.fit(X_train, Y_train)\n",
    "print(\"Training acc:\", boost_reg2.score(X_train, Y_train), \"\\nValidation acc:\",\n",
    "      boost_reg2.score(X_val, Y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
